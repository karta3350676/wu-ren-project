{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df_hh = pd.read_csv(\"./XGboost_archive/hh_demographic.csv\")\n",
    "df_pro = pd.read_csv(r\"./XGboost_archive/product.csv\")\n",
    "df_trans = pd.read_csv(r'./XGboost_archive/transaction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans=df_trans.assign(date=(pd.to_datetime('today')+pd.to_timedelta(df_trans.DAY,unit='D')).dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = df_trans.rename(columns = {'date':'Date'})\n",
    "df_trans['Date'] = df_trans['Date'].apply(lambda x: x.replace(year = x.year - 10))\n",
    "df_trans['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans['Date'] = pd.to_datetime(df_trans['Date'], format=\"%Y-%m-%d \")\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "df_trans[\"Date\"] = df_trans[\"Date\"] + pd.DateOffset(months=1)\n",
    "df_trans['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans['Date'] = pd.to_datetime(df_trans['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tr_pr['Date'] = pd.to_datetime(df_tr_pr['Date'], format=\"%Y-%m-%d \")\n",
    "df_trans['Year'] = df_trans['Date'].dt.year \n",
    "df_trans['Month'] = df_trans['Date'].dt.month \n",
    "df_trans['Day'] = df_trans['Date'].dt.month \n",
    "print(df_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans['Date'] = df_trans['Date'].apply(lambda x : datetime.datetime.strftime(x,\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trans['Date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date_list = df_trans['Date'].tolist()\n",
    "len(Date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mon_Block_list = []\n",
    "for i in Date_list:\n",
    "    tem_list = i.split('-')\n",
    "    if tem_list[0] == '2011':\n",
    "        a = int(tem_list[1])\n",
    "        Mon_Block_list.append(a)\n",
    "    elif tem_list[0] == '2012':\n",
    "        b = int(tem_list[1]) + 12\n",
    "        Mon_Block_list.append(b)\n",
    "    elif tem_list[0] == '2013':\n",
    "        c = int(tem_list[1]) + 24\n",
    "        Mon_Block_list.append(c)\n",
    "len(Mon_Block_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'Mon_Block_num': pd.Series(Mon_Block_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trans['Mon_Block_num'] = pd.DataFrame(data_dict)\n",
    "df_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans['Price_per_Q']= pd.Series(df_trans['SALES_VALUE']/df_trans['QUANTITY']).tolist()\n",
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr = pd.merge(df_trans,df_pro, on='PRODUCT_ID')\n",
    "df_tr_pr.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr[df_tr_pr['SALES_VALUE'] == 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr[df_tr_pr['QUANTITY'] == 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr = df_tr_pr[df_tr_pr['QUANTITY'] > 0]   # 以大於0的資料取代 並檢查後10個\n",
    "df_tr_pr['QUANTITY'].sort_values(ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr = df_tr_pr[df_tr_pr['SALES_VALUE'] > 0]   # 以大於0的資料取代 並檢查後10個\n",
    "df_tr_pr['SALES_VALUE'].sort_values(ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.groupby(\"SUB_COMMODITY_DESC\").sum()[\"QUANTITY\"].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.drop(df_tr_pr[df_tr_pr['SUB_COMMODITY_DESC'] == \"GASOLINE-REG UNLEADED\"].index,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.groupby(\"SUB_COMMODITY_DESC\").sum()[\"QUANTITY\"].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tr_pr.drop(['COUPON_MATCH_DISC','COUPON_DISC','DAY','CURR_SIZE_OF_PRODUCT','TRANS_TIME','CURR_SIZE_OF_PRODUCT'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr[\"SUB_COMMODITY_DESC\"].replace({'SFT DRNK 2 LITER BTL CARB INCL':'SOFT DRINK INCL', 'SOFT DRINKS 12/18&15PK CAN CAR':'SOFT DRINKS CAN','SS ECONOMY ENTREES/DINNERS ALL':'ECONOMY ENTREES DINNERS','PASTA: CANNED':'PASTA CANNED','PREMIUM':'ICE CREAM','DAIRY CASE 100% PURE JUICE - O':'100% PURE JUICE','BEERALEMALT LIQUORS':'BEER','FRZN SS PREMIUM ENTREES/DNRS/N':'PREMIUM ENTREES',\n",
    "                                  'FRZN BAGGED VEGETABLES - PLAIN':'VEGETABLES -PLAIN','CANDY BARS (SINGLES)(INCLUDING':'CANDY BARS'}, inplace=True)\n",
    "df_tr_pr[\"SUB_COMMODITY_DESC\"]    # 替換資料名稱for爬蟲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.groupby(\"SUB_COMMODITY_DESC\").sum()[\"QUANTITY\"].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr['SALES_VALUE'].sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr[df_tr_pr['SALES_VALUE'] == 840.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.drop(df_tr_pr[df_tr_pr['COMMODITY_DESC'] == \"COUPON/MISC ITEMS\"].index,inplace = True) # 因為原始資料我們並不使用折扣卷資料故刪除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr['SALES_VALUE'].sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr[df_tr_pr['SALES_VALUE'] == 631.80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr[df_tr_pr['PRODUCT_ID'] == 948670]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr['Price_per_Q'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.groupby(\"COMMODITY_DESC\").sum()[\"QUANTITY\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.groupby(\"SUB_COMMODITY_DESC\").sum()[\"QUANTITY\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_tr_pr,df_hh, on='household_key') # 合併共三個資料集並確認是否有空值\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"COUPON_DISC\",'COUPON_MATCH_DISC'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date']=df['Date'].astype('int64')  # 轉變型態  (這邊還在考慮是否要丟棄這欄位)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'QUANTITY' in df:\n",
    "    df2 = df.drop(['QUANTITY'] , axis=1) # df2為先把目標值移除的資料\n",
    "\n",
    "\n",
    "#只取 int64, float64 兩種數值型欄位, 存於 num_features 中, 其他類別存於notnum_features\n",
    "num_features = []\n",
    "notnum_features = []\n",
    "for dtype, feature in zip(df2.dtypes, df2.columns):\n",
    "    if dtype == 'float64' or dtype == 'int64':\n",
    "        num_features.append(feature)\n",
    "    else:\n",
    "        notnum_features.append(feature)\n",
    "\n",
    "print(f'lehgth of all featrues : {len(df2.columns)}\\n')\n",
    "print(f'length of Numeric Features : {len(num_features)}\\n Numeric Features : {num_features}\\n')\n",
    "print(f'length of Not Numeric Features : {len(notnum_features)}\\n Not Numeric Features : {notnum_features}')\n",
    "\n",
    "# 削減文字型欄位, 只剩數值型欄位\n",
    "df_train_num = df[num_features]\n",
    "df_train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder().fit_transform(df[df.columns[df.dtypes == object]]) 這行註解\n",
    "df3 = pd.DataFrame()\n",
    "for i in notnum_features:  \n",
    "    df3[i] = LabelEncoder().fit_transform(df2[i]) # 創一個新df , 將原先df在非數值型資料給轉化並寫入(label encoding)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = pd.DataFrame()\n",
    "# for i in notnum_features:\n",
    "#     df3[i] = df2[i]     # 提供one hot encoding 寫法 , 如果不經由先label就執行這個就好\n",
    "#     df3 = pd.get_dummies(df3)\n",
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,f in enumerate(num_features):   # 檢查各資料的離群值 (前面已經有drop一些資料)  (以箱型圖顯示)\n",
    "    ori_series = df2[f].copy()         # 假設有離群值,利用 \"np.log1p\" 去除偏態\n",
    "    qt1 = ori_series.quantile(q=0.25)\n",
    "    qt3 = ori_series.quantile(q=0.75)\n",
    "    iqr = qt3-qt1\n",
    "    ori_series[ori_series>(qt3 + 1.5*iqr)] = qt3 + 1.5*iqr\n",
    "    ori_series[ori_series<(qt1 - 1.5*iqr)] = qt1 - 1.5*iqr\n",
    "    #--------------------------------------------------------#\n",
    "    plt.title(f) \n",
    "    plt.boxplot(ori_series)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#哪些機器學習演算法不需要（需要）做歸一化？\n",
    "#概率模型（樹形模型）不需要歸一化，因為它們不關心變數的值，而是關心變數的分佈和變數之間的條件概率，如決策樹、RF。 而像Adaboost、SVM、LR、Knn、KMeans之類的最優化問題就需要歸一化。\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # 這邊做標準化（Z-Score）創新df 將數值型資料寫入並轉換 (這邊為ndarray)\n",
    "\n",
    "df4 = pd.DataFrame()\n",
    "for i in num_features:    \n",
    "    df4[i] = df2[i]\n",
    "scaler = StandardScaler().fit(df4)\n",
    "df4 = scaler.transform(df4)    \n",
    "df4    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_normal = pd.DataFrame(df4,columns=num_features) # 利用數值型資料關係對應欄位將 'ndarray' 轉為 'Dataframe' \n",
    "df4_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.concat([df3,df4_normal],axis=1)  # 數值型資料(已經normalization)與非數值型資料(已經label encoding)去做合併\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame()  \n",
    "df6['QUANTITY'] = df['QUANTITY']  # 將原本的目標值取回\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con = pd.concat([df5,df6],axis=1)\n",
    "df_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_con.corr()\n",
    "corr['QUANTITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest   # 這邊利用sklearn,f_regression 選擇器去自動選擇我們需要的特徵數\n",
    "from sklearn.feature_selection import f_regression\n",
    "selectKBest = SelectKBest(f_regression,k=10)\n",
    "feature =df_con[['CURR_SIZE_OF_PRODUCT','TRANS_TIME','COMMODITY_DESC','WEEK_NO','Price_per_Q','DAY','BASKET_ID','MARITAL_STATUS_CODE','INCOME_DESC','HOMEOWNER_DESC','HH_COMP_DESC','HOUSEHOLD_SIZE_DESC','KID_CATEGORY_DESC','Mon_Block_num','Day','Month','Year','household_key','PRODUCT_ID','SALES_VALUE','STORE_ID','Date','DEPARTMENT','BRAND','SUB_COMMODITY_DESC','AGE_DESC']]\n",
    "bestFeature =selectKBest.fit_transform(feature,df_con['QUANTITY'])\n",
    "feature.columns[selectKBest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_con.corr()\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_drop = pd.DataFrame(df_con,columns=feature.columns[selectKBest.get_support()]) # 只選取上述篩選的特徵\n",
    "df_con_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_drop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = feature.columns[selectKBest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = np.corrcoef(df_con[cols].values.T)\n",
    "sns.set(font_scale = 1.5)\n",
    "hm = sns.heatmap(corr,cbar=True,annot=True,square=True,fmt=\".2f\",annot_kws={\"size\":15},yticklabels=cols,xticklabels=cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_con_drop['CURR_SIZE_OF_PRODUCT']=df_con_drop['CURR_SIZE_OF_PRODUCT'].astype('object')\n",
    "# df_con_drop['COMMODITY_DESC']=df_con_drop['COMMODITY_DESC'].astype('object')\n",
    "# df_con_drop['HH_COMP_DESC']=df_con_drop['HH_COMP_DESC'].astype('object')\n",
    "# df_con_drop['HOUSEHOLD_SIZE_DESC']=df_con_drop['HOUSEHOLD_SIZE_DESC'].astype('object')\n",
    "# df_con_drop['BRAND']=df_con_drop['BRAND'].astype('object')\n",
    "# df_con_drop['SUB_COMMODITY_DESC']=df_con_drop['SUB_COMMODITY_DESC'].astype('object')\n",
    "\n",
    "df_con_drop.info()  # 這邊將原先非數值資料再轉回物件屬性才可以去做onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded = pd.get_dummies(df_con[df_con.columns[df_con.dtypes == object]])\n",
    "# df_final = pd.concat([encoded, df_con[df_con.columns[df_con.dtypes != object]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df_final = pd.get_dummies(df_con_drop)\n",
    "df_final.head(50)\n",
    "# df_final = pd.get_dummies(df_con_drop[df_con_drop.columns[df_con_drop.dtypes != 'float64']])\n",
    "\n",
    "# for c in df_con_drop[df_con_drop.dtypes != float64]:\n",
    "#     df_final[c] = OneHotEncoder().fit_transform(df_con_drop[c])\n",
    "# df_final.head()\n",
    "\n",
    "# df_final = OneHotEncoder().fit_transform(df_con_drop.loc[:,['CURR_SIZE_OF_PRODUCT','COMMODITY_DESC','HH_COMP_DESC','HOUSEHOLD_SIZE_DESC','BRAND','SUB_COMMODITY_DESC']]).toarray()\n",
    "# df_final.head()\n",
    "\n",
    "# df_final = pd.get_dummies(df_con_drop[['CURR_SIZE_OF_PRODUCT','COMMODITY_DESC','HH_COMP_DESC','HOUSEHOLD_SIZE_DESC','BRAND','SUB_COMMODITY_DESC']])\n",
    "# df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# # from sklearn.ensemble.forest import RandomForestClassifier\n",
    "# # from sklearn import datasets, cross_validation, ensemble \n",
    "# X = df_final\n",
    "# y = df6\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_leaf_options = [1,5,10,50,100,200,500]\n",
    "# for leaf_size in sample_leaf_options :\n",
    "#     rf = RandomForestRegressor( n_estimators = 200, oob_score = True , n_jobs = -1,random_state =50,\n",
    "#                                 max_features = \"auto\", min_samples_leaf = leaf_size)\n",
    "# # rf = RandomForestRegressor(n_estimators=200, min_samples_split=9, min_samples_leaf=leaf_size, \n",
    "# #                            max_features=\"auto\", max_depth=8, bootstrap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機森林預測\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model_rf = rf.fit(X_train, y_train)\n",
    "rf_pred = model_rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(rf_pred,y_test, squared=False)\n",
    "print(mse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, rf_pred)\n",
    "print('accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_samples = accuracy_score(y_test, rf_pred, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(y_test, rf_pred), index = list(set(y)), columns = list(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(cm, annot = True, fmt=\"d\",cmap=sns.color_palette(\"GnBu\"))\n",
    "            .set(xlabel='predicted values', ylabel='real values', \n",
    "             title = 'Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.to_csv(r'final_no_onehot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
